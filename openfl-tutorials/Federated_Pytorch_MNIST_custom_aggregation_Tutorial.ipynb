{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Federated PyTorch MNIST Tutorial"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Install dependencies if not already installed\n",
    "!pip install torch torchvision"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (831.4 MB)\n",
      "\u001b[K     |████▌                           | 116.8 MB 1.0 MB/s eta 0:11:25"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import openfl.native as fx\n",
    "from openfl.federated import FederatedModel,FederatedDataSet\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After importing the required packages, the next step is setting up our openfl workspace. To do this, simply run the `fx.init()` command as follows:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Setup default workspace, logging, etc.\n",
    "fx.init('torch_cnn_mnist')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def one_hot(labels, classes):\n",
    "    return np.eye(classes)[labels]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_images,train_labels = trainset.train_data, np.array(trainset.train_labels)\n",
    "train_images = torch.from_numpy(np.expand_dims(train_images, axis=1)).float()\n",
    "train_labels = one_hot(train_labels,10)\n",
    "\n",
    "validset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "valid_images,valid_labels = validset.test_data, np.array(validset.test_labels)\n",
    "valid_images = torch.from_numpy(np.expand_dims(valid_images, axis=1)).float()\n",
    "valid_labels = one_hot(valid_labels,10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from openfl.utilities.types import Metric\n",
    "\n",
    "feature_shape = train_images.shape[1]\n",
    "classes       = 10\n",
    "\n",
    "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 32)\n",
    "        self.fc2 = nn.Linear(32, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fedcurv = FedCurv(importance=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def train_epoch(self, batch_generator):\n",
    "        \"\"\"Train single epoch.\n",
    "\n",
    "        Override this function in order to use custom training.\n",
    "\n",
    "        Args:\n",
    "            batch_generator: Train dataset batch generator. Yields (samples, targets) tuples of\n",
    "            size = `self.data_loader.batch_size`.\n",
    "        Returns:\n",
    "            Metric: An object containing name and np.ndarray value.\n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        self.fedcurv.update_snapshots(self)\n",
    "        for data, target in batch_generator:\n",
    "            data, target = torch.tensor(data).to(self.device), torch.tensor(\n",
    "                target).to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self(data)\n",
    "            loss = self.loss_fn(output=output, target=target) + self.fedcurv.importance * self.fedcurv.penalty(self)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "        loss = np.mean(losses)\n",
    "        return Metric(name=self.loss_fn.__name__, value=np.array(loss))\n",
    "\n",
    "optimizer = lambda x: optim.Adam(x, lr=1e-4)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    \"\"\"Binary cross-entropy metric\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(input=output,target=torch.argmax(target, dim=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "#Create a federated model using the pytorch class, lambda optimizer function, and loss function\n",
    "fl_model = FederatedModel(build_model=Net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with openfl. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=10)\n",
    "collaborators = {str(i): collaborator_models[i] for i in range(10)}#, 'three':collaborator_models[2]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Original MNIST dataset\n",
    "print(f'Original training data size: {len(train_images)}')\n",
    "print(f'Original validation data size: {len(valid_images)}\\n')\n",
    "\n",
    "#Collaborator one's data\n",
    "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
    "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator two's data\n",
    "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
    "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator three's data\n",
    "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
    "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the current plan values by running the `fx.get_plan()` function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " #Get the current values of the plan. Each of these can be overridden\n",
    "print(fx.get_plan())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are ready to run our experiment. If we want to pass in custom plan settings, we can easily do that with the `override_config` parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from openfl.component.aggregation_functions import AggregationFunctionInterface\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def variable(t: torch.Tensor, use_cuda=True, **kwargs):\n",
    "    if torch.cuda.is_available() and use_cuda:\n",
    "        t = t.cuda()\n",
    "    return Variable(t, **kwargs)\n",
    "\n",
    "class FedCurv:\n",
    "    def __init__(self, importance):\n",
    "        self.importance = importance\n",
    "        \n",
    "    def update_snapshots(self, model, samples):\n",
    "        self._snapshots = {n: variable(p.data) for n, p in deepcopy(model.named_parameters())}\n",
    "        self._precision_matrices = self.get_fisher_diag(model, samples)\n",
    "    \n",
    "    def _get_fisher_diag(self, model, samples):\n",
    "        precision_matrices = {}\n",
    "        for n, p in deepcopy(model.named_parameters()):\n",
    "            if p.requires_grad:\n",
    "                p.data.zero_()\n",
    "                precision_matrices[n] = variable(p.data)\n",
    "\n",
    "        model.eval()\n",
    "        for sample in samples:\n",
    "            model.zero_grad()\n",
    "            sample = variable(sample)\n",
    "            output = model(sample).view(1, -1)\n",
    "            label = output.max(1)[1].view(-1)\n",
    "            loss = F.nll_loss(F.log_softmax(output, dim=1), label)\n",
    "            loss.backward()\n",
    "\n",
    "            for n, p in model.named_parameters():\n",
    "                precision_matrices[n].data += p.grad.data ** 2 / len(samples)\n",
    "\n",
    "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
    "        return precision_matrices\n",
    "\n",
    "    def penalty(self, model: nn.Module):\n",
    "        loss = 0\n",
    "        for n, p in model.named_parameters():\n",
    "            _loss = self._precision_matrices[n] * (p - self._snapshots[n]) ** 2\n",
    "            loss += _loss.sum()\n",
    "        return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from openfl.component.aggregation_functions import AggregationFunctionInterface\n",
    "import numpy as np\n",
    "\n",
    "class ClippedAveraging(AggregationFunctionInterface):\n",
    "    def __init__(self, ratio):\n",
    "        \"\"\"Average clipped tensors.\n",
    "            \n",
    "            Args:\n",
    "                ratio(float): Ratio to multiply with a tensor for clipping\n",
    "        \"\"\"\n",
    "        self.ratio = ratio\n",
    "        \n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             db_iterator,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             *__):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        clipped_tensors = []\n",
    "        previous_tensor_value = None\n",
    "        for record in db_iterator:\n",
    "            if (\n",
    "                record['round'] == (fl_round - 1)\n",
    "                and record['tensor_name'] == tensor_name\n",
    "                and 'aggregated' in record['tags']\n",
    "                and 'delta' not in record['tags']\n",
    "               ):\n",
    "                previous_tensor_value = record['nparray']\n",
    "        weights = []\n",
    "        for local_tensor in local_tensors:\n",
    "            prev_tensor = previous_tensor_value if previous_tensor_value is not None else local_tensor.tensor\n",
    "            delta = local_tensor.tensor - prev_tensor\n",
    "            new_tensor = prev_tensor + delta * self.ratio\n",
    "            clipped_tensors.append(new_tensor)\n",
    "            weights.append(local_tensor.weight)\n",
    "\n",
    "        return np.average(clipped_tensors, weights=weights, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from openfl.component.aggregation_functions import AggregationFunctionInterface\n",
    "\n",
    "class ConditionalThresholdAveraging(AggregationFunctionInterface):\n",
    "    def __init__(self, threshold_fn, metric_name='acc', tags=['metric', 'validate_local']):\n",
    "        \"\"\"Average tensors by metric value on previous round.\n",
    "        If no tensors match threshold condition, a simple weighted averaging will be performed.\n",
    "           \n",
    "           Args:\n",
    "               threshold_fn(callable): function to define a threshold for each round.\n",
    "                   Has single argument `round_number`. \n",
    "                   Returns threshold value above which collaborators are allowed to participate in aggregation.\n",
    "               metric_name(str): name of the metric to trace. Can be either 'acc' or 'loss'.\n",
    "               tags(Tuple[str]): tags of the metric tensor.\n",
    "        \"\"\"\n",
    "        self.metric_name = metric_name\n",
    "        self.threshold_fn = threshold_fn\n",
    "        self.tags = tags\n",
    "        self.logged_round = -1\n",
    "        \n",
    "    def call(self,\n",
    "             local_tensors,\n",
    "             db_iterator,\n",
    "             tensor_name,\n",
    "             fl_round,\n",
    "             *__):\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        selected_tensors = []\n",
    "        selected_weights = []\n",
    "        for record in db_iterator:\n",
    "            for local_tensor in local_tensors:\n",
    "                tags = set(self.tags + [local_tensor.col_name])\n",
    "                if (\n",
    "                    tags <= set(record['tags']) \n",
    "                    and record['round'] == fl_round\n",
    "                    and record['tensor_name'] == self.metric_name\n",
    "                    and record['nparray'] >= self.threshold_fn(fl_round)\n",
    "                ):\n",
    "                    selected_tensors.append(local_tensor.tensor)\n",
    "                    selected_weights.append(local_tensor.weight)\n",
    "        if not selected_tensors:\n",
    "            if self.logged_round < fl_round:\n",
    "                fx.logger.warning('No collaborators match threshold condition. Performing simple averaging...')\n",
    "            selected_tensors = [local_tensor.tensor for local_tensor in local_tensors]\n",
    "            selected_weights = [local_tensor.weight for local_tensor in local_tensors]\n",
    "        if self.logged_round < fl_round:\n",
    "            self.logged_round += 1\n",
    "        return np.average(selected_tensors, weights=selected_weights, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(collaborators,\n",
    "                                   {\n",
    "                                       'aggregator.settings.rounds_to_train':5,\n",
    "                                       'aggregator.settings.db_store_rounds':5,\n",
    "                                       'tasks.train.aggregation_type': ConditionalThresholdAveraging(lambda round_num: 0.85 + 0.03 * round_num)\n",
    "                                   })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Save final model\n",
    "final_fl_model.save_native('final_pytorch_model')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('ewc': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "f646378d3ad4a45da028b9e2fbfc24021cf7e2072344e117fd324139b23d6dc5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}